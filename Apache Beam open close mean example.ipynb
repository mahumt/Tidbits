{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/hands-on-apache-beam-building-data-pipelines-in-python-6548898b66a5\n",
    "#https://github.com/vincentteyssier/apache-beam-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining custom arguments\n",
    "class MyOptions(PipelineOptions):    \n",
    "  @classmethod\n",
    "  def _add_argparse_args(cls, parser):\n",
    "    parser.add_argument('--input',\n",
    "                        help='Input for the pipeline',\n",
    "                        default='./data/')\n",
    "    parser.add_argument('--output',\n",
    "                        help='Output for the pipeline',\n",
    "                        default='./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to split a csv line by elements and keep only the columns we are interested in \n",
    "class Split(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        Date,Open,High,Low,Close,Volume = element.split(\",\")\n",
    "        return [{\n",
    "            'Date': Date,\n",
    "            'Open': float(Open),\n",
    "            'Close': float(Close)\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectOpen(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        # Returns a list of tuples containing the 1 key and Open value\n",
    "        result = [(1, element['Open'])]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectClose(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        # Returns a list of tuples containing the 1 key and Close value\n",
    "        result = [(1, element['Close'])]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to calculate the standard deviation over an entire PCollection\n",
    "class Standard_deviation(beam.DoFn):\n",
    "    def create_accumulator(self):\n",
    "        return (0.0, 0.0, 0) # x, x^2, count\n",
    "\n",
    "    def add_input(self, sum_count, input):\n",
    "        (sum, sumsq, count) = sum_count\n",
    "        return sum + input, sumsq + input*input, count + 1\n",
    "\n",
    "    def merge_accumulators(self, accumulators):\n",
    "        sums, sumsqs, counts = zip(*accumulators)\n",
    "        return sum(sums), sum(sumsqs), sum(counts)\n",
    "\n",
    "    def extract_output(self, sum_count):\n",
    "        (sum, sumsq, count) = sum_count\n",
    "        if count:\n",
    "            mean = sum / count\n",
    "            variance = (sumsq / count) - mean*mean\n",
    "            stddev = np.sqrt(variance) if variance > 0 else 0\n",
    "            return {\n",
    "                'mean': mean,\n",
    "                'variance': variance,\n",
    "                'stddev': stddev,\n",
    "                'count': count\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'mean': float('NaN'),\n",
    "                'variance': float('NaN'),\n",
    "                'stddev': float('NaN'),\n",
    "                'count': 0\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting input and output files\n",
    "input_filename = \"data/sp500.csv\"\n",
    "output_filename = \"data/result.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the pipeline\n",
    "options = PipelineOptions()\n",
    "\n",
    "with beam.Pipeline(options=options) as p:\n",
    "    # reading the csv and splitting lines by elements we want to retain\n",
    "    csv_lines = (\n",
    "            p | beam.io.ReadFromText(input_filename, skip_header_lines=1) |\n",
    "            beam.ParDo(Split())\n",
    "        )\n",
    "\n",
    "    # calculate the mean for Open values\n",
    "    mean_open = (\n",
    "        csv_lines | beam.ParDo(CollectOpen()) |\n",
    "        \"Grouping keys Open\" >> beam.GroupByKey() |\n",
    "        \"Calculating mean for Open\" >> beam.CombineValues(\n",
    "            beam.combiners.MeanCombineFn()\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # calculate the mean for Close values\n",
    "    mean_close = (\n",
    "        csv_lines | beam.ParDo(CollectClose()) |\n",
    "        \"Grouping keys Close\" >> beam.GroupByKey() |\n",
    "        \"Calculating mean for Close\" >> beam.CombineValues(\n",
    "            beam.combiners.MeanCombineFn()\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # writing results to file\n",
    "    output= ( \n",
    "        { \n",
    "            'Mean Open': mean_open,\n",
    "            'Mean Close': mean_close \n",
    "        } | \n",
    "        beam.CoGroupByKey() | \n",
    "        beam.io.WriteToText(output_filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
